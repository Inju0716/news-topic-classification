{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1920,
     "status": "ok",
     "timestamp": 1604741039002,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "d1SXMQ_PNW0x",
    "outputId": "c5e3bcdb-4b2a-4592-8c6d-86c9422ceb3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy \n",
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install konlpy JPype1-py3\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "\n",
    "# gensim \n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DilHyUrcrNR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors\n",
    "from typing import List\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRF587luN3Kp"
   },
   "outputs": [],
   "source": [
    "#train data, test data 로드\n",
    "data_path_train = \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_train.csv\"\n",
    "data_path_test= \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_path_train, sep = ',')\n",
    "df_test = pd.read_csv(data_path_test, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S94AjnKu163"
   },
   "outputs": [],
   "source": [
    "# 불용어 처리 (길호현 (2018). 텍스트마이닝을 위한 한국어 불용어 목록 연구. 우리말글 , 78, 1-25 에 나와있는 불용어 사용. 본 공개코드에선 삭제)\n",
    "str_stopwords=\"불용어 입력\"\n",
    "stopwords=str_stopwords.split('\\t ')\n",
    "\n",
    "# tokenizer 함수 정의\n",
    "mecab=Mecab()\n",
    "def tokenizer_morphs(string):\n",
    "    string.replace(\"…\", \"\")\n",
    "    string.replace(\"·\", \"\")\n",
    "    nouns = mecab.nouns(string) # 명사만 추출\n",
    "    nouns = [a for a in nouns if (len(a) >1 and a not in stopwords) ]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypVMiZFvavED"
   },
   "source": [
    "### 3. Field 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, LabelField, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BgIwbNcVO6i"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenizer_morphs, lower=True, include_lengths = True) #Text 처리하는 방법을 정의\n",
    "LABEL = LabelField(dtype=torch.int64) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-nm983la2zl"
   },
   "source": [
    "### 4. TabularDataset 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHs7OjgpYNrx"
   },
   "outputs": [],
   "source": [
    "raw_datafields = [(\"filename\", None), # 사용하지 않는 것들은 None\n",
    "                 (\"date\", None), (\"NewsPaper\", None),\n",
    "                 (\"Topic\", LABEL), (\"News\", TEXT)] # Topic을 위에서 정의한 LABEL로, News를 위에서 정의한 TEXT로 처리할 것임 \n",
    "\n",
    "train_data = TabularDataset(\n",
    "        path=data_path_train,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)\n",
    "\n",
    "test_data= TabularDataset(\n",
    "        path=data_path_test,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x60f5nBx5xrI"
   },
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=10)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58495,
     "status": "ok",
     "timestamp": 1604741095949,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "UKOj-h-683HM",
    "outputId": "5ba43d94-1e63-49f4-82a4-1d7af7001797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f63ac0b5620>, {'IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 사전학습 임베딩 불러오기 \n",
    "Reference: https://rohit-agrawal.medium.com/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDP4WfCGgMVQ"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "path = '/content/gdrive/My Drive/dataset/'\n",
    "Word2Vec_300D_token_model = KeyedVectors.load_word2vec_format(path + 'Word2Vec_300D_token.model', binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "a93a6d4432df401c83937fa7ca12f2fd",
      "7b5022072b4c46408c79d26a522557d9",
      "e6e6066b0b874eb3b64d68dd06d88593",
      "2e42ec407de04fd5881545a031758b33",
      "4918b279bfd94381bcb6119ef4c50407",
      "9e6d3fde429c431fbe158163f3a7e582",
      "f7ba629e5b554de49cb0902df9eb10e8",
      "673deeee229c4bee85d4981c808be7f5"
     ]
    },
    "executionInfo": {
     "elapsed": 61052,
     "status": "ok",
     "timestamp": 1604741098525,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "GEFynT5k56Oz",
    "outputId": "048e3d2b-6d69-4202-88de-d63ca676850b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93a6d4432df401c83937fa7ca12f2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14639.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_vectors = []\n",
    "\n",
    "for token, idx in tqdm_notebook(TEXT.vocab.stoi.items()):\n",
    "    if token in Word2Vec_300D_token_model.wv.vocab.keys(): #사전학습 임베딩 모델에 해당 토큰의 임베딩 값이 있을 경우 그 값을 가져옴\n",
    "        word2vec_vectors.append(torch.FloatTensor(Word2Vec_300D_token_model[token]))\n",
    "    else:\n",
    "        word2vec_vectors.append(torch.randn(300)) #사전학습 임베딩 모델에 임베딩 값이 없을 경우 랜덤으로 설정\n",
    "        \n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi, word2vec_vectors, 300) #Vocab 각 토큰의 임베딩 값 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Iterator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZWB5Hc4pu_c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=lambda x: len(x.News), #데이터를 그룹화하는데 사용하는 함수\n",
    " sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6ORHo2kwSJO"
   },
   "source": [
    "### 8. LSTM Model 정의\n",
    "Reference: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sT9pIolf6zF_"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0O48JJ6HwQNL"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUIrxfOLwoDY"
   },
   "outputs": [],
   "source": [
    "#parameters 설정\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 9\n",
    "N_LAYERS= 2\n",
    "BIDIRECTIONAL= True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#모델에 parameters 입력\n",
    "model = LSTM(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60873,
     "status": "ok",
     "timestamp": 1604741098538,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "sSI1Tb9KxHJH",
    "outputId": "df38069c-f4c8-4b35-cee9-ed176d981a2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3605e+00,  1.6792e+00, -2.4476e-01,  ..., -3.4673e-01,\n",
       "          1.9876e-01, -4.5431e-01],\n",
       "        [-4.8776e-03,  9.8222e-01, -8.1195e-01,  ...,  3.8007e-01,\n",
       "         -9.4967e-01, -4.0274e-01],\n",
       "        [ 9.8296e-02,  6.8959e-02, -9.7626e-02,  ...,  1.9529e-02,\n",
       "         -4.3655e-02,  5.1375e-02],\n",
       "        ...,\n",
       "        [-2.6780e-02, -4.1724e-02,  1.4282e-01,  ..., -1.1069e-02,\n",
       "         -1.3842e-02,  5.1257e-02],\n",
       "        [-5.7113e-02, -1.0315e-01,  1.0424e-01,  ..., -6.7090e-02,\n",
       "          3.6692e-02,  4.1873e-02],\n",
       "        [-7.6801e-02, -3.9502e-02,  7.4451e-04,  ...,  4.1259e-02,\n",
       "          2.8716e-03,  5.0831e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사전학습 임베딩값 가져오기\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuJRrWw-zSHI"
   },
   "outputs": [],
   "source": [
    "#<pad> 토큰에 대해 초기 임베딩값을 0으로 설정\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BecAUQtY28lS"
   },
   "source": [
    "### 9. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1osmRp1272N"
   },
   "outputs": [],
   "source": [
    "# optimizer와 loss function 정의\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyvIg-gL3HON"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4zn8Bnt3_ra"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text, text_lengths = batch.News\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Topic)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.Topic)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cJaQ6dGyuu5"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.News\n",
    "           \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.Topic)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.Topic)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZztHqeo4Mnt"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201189,
     "status": "ok",
     "timestamp": 1604741239066,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "a1R6gm194VeQ",
    "outputId": "62295aa4-b7d3-4151-a539-2a261f3694a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 1.803 | Train Acc: 28.87%\n",
      "Epoch: 02 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 1.061 | Train Acc: 61.91%\n",
      "Epoch: 03 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.655 | Train Acc: 78.18%\n",
      "Epoch: 04 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.423 | Train Acc: 87.08%\n",
      "Epoch: 05 | Epoch Time: 0m 14s\n",
      "\tTrain Loss: 0.289 | Train Acc: 91.33%\n",
      "Epoch: 06 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.198 | Train Acc: 94.19%\n",
      "Epoch: 07 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.136 | Train Acc: 95.92%\n",
      "Epoch: 08 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.095 | Train Acc: 97.25%\n",
      "Epoch: 09 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.094 | Train Acc: 97.21%\n",
      "Epoch: 10 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.059 | Train Acc: 98.39%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    #valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if train_loss < best_train_loss:\n",
    "      best_train_loss = train_loss\n",
    "      torch.save(model.state_dict(), 'LSTM-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201169,
     "status": "ok",
     "timestamp": 1604741239072,
     "user": {
      "displayName": "­박재은 / 학생 / 심리학과",
      "photoUrl": "",
      "userId": "00567750484884375615"
     },
     "user_tz": -540
    },
    "id": "G7NIglO1brEK",
    "outputId": "d16b367b-0cf4-40aa-feef-9d945b0d752c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.082 | Test Acc: 78.49%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('LSTM-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFaKhJIkMd1N"
   },
   "source": [
    "### 11. User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHSn2kQiMd1P"
   },
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer_morphs(sentence)\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length = [len(indexed)]\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    preds = model(tensor, length_tensor)\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "    return max_preds.item()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "시도3(2-layer bidirectional LSTM - Word2Vec형태소).ipynb",
   "provenance": [
    {
     "file_id": "1i9tG8KnoLQGvGnSRpZwIwsUI28iZOkmL",
     "timestamp": 1604735507632
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2e42ec407de04fd5881545a031758b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_673deeee229c4bee85d4981c808be7f5",
      "placeholder": "​",
      "style": "IPY_MODEL_f7ba629e5b554de49cb0902df9eb10e8",
      "value": " 14639/14639 [00:00&lt;00:00, 75220.26it/s]"
     }
    },
    "4918b279bfd94381bcb6119ef4c50407": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "673deeee229c4bee85d4981c808be7f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b5022072b4c46408c79d26a522557d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e6d3fde429c431fbe158163f3a7e582": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93a6d4432df401c83937fa7ca12f2fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6e6066b0b874eb3b64d68dd06d88593",
       "IPY_MODEL_2e42ec407de04fd5881545a031758b33"
      ],
      "layout": "IPY_MODEL_7b5022072b4c46408c79d26a522557d9"
     }
    },
    "e6e6066b0b874eb3b64d68dd06d88593": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e6d3fde429c431fbe158163f3a7e582",
      "max": 14639,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4918b279bfd94381bcb6119ef4c50407",
      "value": 14639
     }
    },
    "f7ba629e5b554de49cb0902df9eb10e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
