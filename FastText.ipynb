{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPK8vIinFAh1",
    "outputId": "60a8f23f-ed95-40e1-c9a7-1b6c4b2682c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy \n",
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install konlpy JPype1-py3\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "\n",
    "# gensim \n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec9n4vd6OPwB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab\n",
    "from typing import List\n",
    "import itertools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xV0eOlsAIMcQ"
   },
   "outputs": [],
   "source": [
    "#train data, test data 로드\n",
    "data_path_train = \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_train.csv\"\n",
    "data_path_test= \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_path_train, sep = ',')\n",
    "df_test = pd.read_csv(data_path_test, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1z4I3ZlBlUl"
   },
   "source": [
    "### 2. 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT2-R44sKeNj"
   },
   "outputs": [],
   "source": [
    "# 불용어 처리 (길호현 (2018). 텍스트마이닝을 위한 한국어 불용어 목록 연구. 우리말글 , 78, 1-25 에 나와있는 불용어 사용. 본 공개코드에선 삭제)\n",
    "str_stopwords=\"불용어 입력\"\n",
    "stopwords=str_stopwords.split('\\t ')\n",
    "\n",
    "# tokenizer 함수 정의\n",
    "mecab=Mecab()\n",
    "def tokenizer_morphs(string):\n",
    "    string.replace(\"…\", \"\")\n",
    "    string.replace(\"·\", \"\")\n",
    "    nouns = mecab.nouns(string) # 명사만 추출\n",
    "    nouns = [a for a in nouns if (len(a) >1 and a not in stopwords) ]\n",
    "    return nouns\n",
    "\n",
    "# bigram 함수 정의 (ref: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb)\n",
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGOsEqQd9JTx"
   },
   "source": [
    "### 3. Field 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jU_o4gRmOCgM"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, LabelField, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cN0IsWMPM_Di"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer_morphs, preprocessing = generate_bigrams)\n",
    "LABEL = data.LabelField(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0f7K0Pm9Pdk"
   },
   "source": [
    "### 4. TabularDataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irGcD4t8Pi4p"
   },
   "outputs": [],
   "source": [
    "raw_datafields = [(\"filename\", None), \n",
    "                 (\"date\", None), (\"NewsPaper\", None),\n",
    "                 (\"Topic\", LABEL), (\"News\", TEXT)] \n",
    "\n",
    "train_data = TabularDataset(\n",
    "        path=data_path_train,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)\n",
    "\n",
    "test_data= TabularDataset(\n",
    "        path=data_path_test,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsYL1PWe9tLO"
   },
   "source": [
    "### 5. Vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfyyORrVQSLs"
   },
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=10)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 사전학습 임베딩 불러오기\n",
    "Reference: https://rohit-agrawal.medium.com/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFJjqSdxBskO"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#형태소 기반 word2vec 임베딩 사용\n",
    "path = '/content/gdrive/My Drive/model/'\n",
    "Word2Vec_300D_token_model = KeyedVectors.load_word2vec_format(path + 'Word2Vec_300D_token.model', binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210,
     "referenced_widgets": [
      "5ff5ded7abf541639146fd6e1421c343",
      "d7480b01b8314aa6ac8340bfb2a51f38",
      "7b153d2c026344528a63554511e6b590",
      "eb6fa85838074d99b6442856914effd5",
      "675c4e1dc35c495288623f921f66607a",
      "ea0e685a070048d890d7878d68659d95",
      "4ac5a5dc66104d1880a049be65f01a48",
      "4dcd17dcedf449369fe379d6ff783007"
     ]
    },
    "id": "Zv6nIfNnQyj_",
    "outputId": "86e9e44b-5253-4f70-8c6b-ee8a4aea59a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff5ded7abf541639146fd6e1421c343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22873.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_vectors = []\n",
    "\n",
    "for token, idx in tqdm_notebook(TEXT.vocab.stoi.items()):\n",
    "    if token in Word2Vec_300D_token_model.wv.vocab.keys(): #사전학습 임베딩 모델에 해당 토큰의 임베딩 값이 있을 경우 그 값을 가져옴\n",
    "        word2vec_vectors.append(torch.FloatTensor(Word2Vec_300D_token_model[token]))\n",
    "    else:\n",
    "        word2vec_vectors.append(torch.randn(300)) #사전학습 임베딩 모델에 임베딩 값이 없을 경우 랜덤으로 설정\n",
    "        \n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi, word2vec_vectors, 300) #Vocab 각 토큰의 임베딩 값 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAmwJZtW9yVR"
   },
   "source": [
    "### 7. Iterator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuKysCqyQbSJ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=lambda x: len(x.News), #데이터를 그룹화하는데 사용하는 함수\n",
    "    sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGsrgeUGOljI"
   },
   "source": [
    "### 8. FastText Model 정의\n",
    "Reference: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIJ0fMzOJyL-"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuZ40jVLBK31"
   },
   "outputs": [],
   "source": [
    "#parameters 설정\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#모델에 parameters 입력\n",
    "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvpr2MYcBoBa",
    "outputId": "e8fc9e5c-a741-4635-ca06-73bc06723583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,864,609 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#parameter 수 확인\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqDWcK3OKD9Z",
    "outputId": "30c2f7aa-2166-4573-bd95-8bbbdc4282df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6938e+00,  9.5898e-01, -5.5622e-01,  ...,  8.2150e-01,\n",
       "         -1.9667e-01, -9.8671e-02],\n",
       "        [ 7.3189e-01, -1.1772e-01, -1.2516e+00,  ..., -1.8687e-02,\n",
       "         -1.1934e+00,  2.6147e-01],\n",
       "        [ 9.8296e-02,  6.8959e-02, -9.7626e-02,  ...,  1.9529e-02,\n",
       "         -4.3655e-02,  5.1375e-02],\n",
       "        ...,\n",
       "        [-5.7113e-02, -1.0315e-01,  1.0424e-01,  ..., -6.7090e-02,\n",
       "          3.6692e-02,  4.1873e-02],\n",
       "        [-7.6801e-02, -3.9502e-02,  7.4451e-04,  ...,  4.1259e-02,\n",
       "          2.8716e-03,  5.0831e-02],\n",
       "        [-1.2414e+00, -1.6570e-01, -1.3894e-01,  ..., -9.1861e-02,\n",
       "         -5.1316e-01,  1.0526e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델에 사전학습 임베딩값 가져오기\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGYwg6sDhSRU"
   },
   "outputs": [],
   "source": [
    "#<pad> 토큰에 대해 초기 임베딩값을 0으로 설정 \n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADPu8gIQMi4Y"
   },
   "source": [
    "### 9. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Jf4YgNZBhL5"
   },
   "outputs": [],
   "source": [
    "#optimizer와 loss function 정의\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptjsbAcEBhgy"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3dP-Q9qBh17"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.News)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Topic)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.Topic)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQxlAJu3SBSK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.News)\n",
    "            \n",
    "            loss = criterion(predictions, batch.Topic)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.Topic)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U8byKefNO32"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O27Oa0A9NO6w",
    "outputId": "6a003ea2-e95d-42d9-b202-fe3a64a18c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 2.172 | Train Acc: 14.99%\n",
      "Epoch: 02 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 2.099 | Train Acc: 32.08%\n",
      "Epoch: 03 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.954 | Train Acc: 53.40%\n",
      "Epoch: 04 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.729 | Train Acc: 61.29%\n",
      "Epoch: 05 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.464 | Train Acc: 70.16%\n",
      "Epoch: 06 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.221 | Train Acc: 75.69%\n",
      "Epoch: 07 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.036 | Train Acc: 79.32%\n",
      "Epoch: 08 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.890 | Train Acc: 80.90%\n",
      "Epoch: 09 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.780 | Train Acc: 82.87%\n",
      "Epoch: 10 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.690 | Train Acc: 84.67%\n",
      "Epoch: 11 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.613 | Train Acc: 85.73%\n",
      "Epoch: 12 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.555 | Train Acc: 87.09%\n",
      "Epoch: 13 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.500 | Train Acc: 88.33%\n",
      "Epoch: 14 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.454 | Train Acc: 89.30%\n",
      "Epoch: 15 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.415 | Train Acc: 90.45%\n",
      "Epoch: 16 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.381 | Train Acc: 91.26%\n",
      "Epoch: 17 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.349 | Train Acc: 92.27%\n",
      "Epoch: 18 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.320 | Train Acc: 93.05%\n",
      "Epoch: 19 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.294 | Train Acc: 93.79%\n",
      "Epoch: 20 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.271 | Train Acc: 94.38%\n",
      "Epoch: 21 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.249 | Train Acc: 95.04%\n",
      "Epoch: 22 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.228 | Train Acc: 95.66%\n",
      "Epoch: 23 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.212 | Train Acc: 96.17%\n",
      "Epoch: 24 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.194 | Train Acc: 96.64%\n",
      "Epoch: 25 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.179 | Train Acc: 97.08%\n",
      "Epoch: 26 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.168 | Train Acc: 97.45%\n",
      "Epoch: 27 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.151 | Train Acc: 97.95%\n",
      "Epoch: 28 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.141 | Train Acc: 98.11%\n",
      "Epoch: 29 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.128 | Train Acc: 98.43%\n",
      "Epoch: 30 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.118 | Train Acc: 98.72%\n",
      "Epoch: 31 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.110 | Train Acc: 98.80%\n",
      "Epoch: 32 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.100 | Train Acc: 99.10%\n",
      "Epoch: 33 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.091 | Train Acc: 99.23%\n",
      "Epoch: 34 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.086 | Train Acc: 99.39%\n",
      "Epoch: 35 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.079 | Train Acc: 99.53%\n",
      "Epoch: 36 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.072 | Train Acc: 99.64%\n",
      "Epoch: 37 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.067 | Train Acc: 99.72%\n",
      "Epoch: 38 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.061 | Train Acc: 99.79%\n",
      "Epoch: 39 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.058 | Train Acc: 99.83%\n",
      "Epoch: 40 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.052 | Train Acc: 99.87%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 40\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "    torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TF7fozeNKCQ",
    "outputId": "b99a4166-57db-411a-c462-a88f78ce371f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.457 | Test Acc: 84.58%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut5-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFl46_JshSRX"
   },
   "source": [
    "\n",
    "\n",
    "### 11. User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9HKq7NQhSRY"
   },
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer_morphs(sentence)\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "    return max_preds.item()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MidTermProject_CL_Group2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4ac5a5dc66104d1880a049be65f01a48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dcd17dcedf449369fe379d6ff783007": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ff5ded7abf541639146fd6e1421c343": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b153d2c026344528a63554511e6b590",
       "IPY_MODEL_eb6fa85838074d99b6442856914effd5"
      ],
      "layout": "IPY_MODEL_d7480b01b8314aa6ac8340bfb2a51f38"
     }
    },
    "675c4e1dc35c495288623f921f66607a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b153d2c026344528a63554511e6b590": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea0e685a070048d890d7878d68659d95",
      "max": 22873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_675c4e1dc35c495288623f921f66607a",
      "value": 22873
     }
    },
    "d7480b01b8314aa6ac8340bfb2a51f38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea0e685a070048d890d7878d68659d95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb6fa85838074d99b6442856914effd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dcd17dcedf449369fe379d6ff783007",
      "placeholder": "​",
      "style": "IPY_MODEL_4ac5a5dc66104d1880a049be65f01a48",
      "value": " 22873/22873 [00:00&lt;00:00, 67649.44it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
