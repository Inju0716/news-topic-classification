{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1SXMQ_PNW0x",
    "outputId": "741cb8f8-e48a-4c54-90cc-5ad6308482be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy \n",
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install konlpy JPype1-py3\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "\n",
    "# gensim \n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xcd9YV9U71f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors\n",
    "from typing import List\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRF587luN3Kp"
   },
   "outputs": [],
   "source": [
    "#train data, test data path 설정, 확인\n",
    "data_path_test= \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_test.csv\"\n",
    "data_path_train = \"/content/gdrive/My Drive/dataset/BalancedNewsCorpus/BalancedNewsCorpus_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_path_train, sep = ',')\n",
    "df_test = pd.read_csv(data_path_test, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE9d1mYBOkZw"
   },
   "outputs": [],
   "source": [
    "# 불용어 처리 (길호현 (2018). 텍스트마이닝을 위한 한국어 불용어 목록 연구. 우리말글 , 78, 1-25 에 나와있는 불용어 사용. 본 공개코드에선 삭제)\n",
    "str_stopwords=\"불용어 입력\"\n",
    "stopwords=str_stopwords.split('\\t ')\n",
    "\n",
    "# tokenizer 함수 정의\n",
    "mecab=Mecab()\n",
    "def tokenizer_morphs(string):\n",
    "    string.replace(\"…\", \"\")\n",
    "    string.replace(\"·\", \"\")\n",
    "    nouns = mecab.nouns(string) # 명사만 추출\n",
    "    nouns = [a for a in nouns if (len(a) >1 and a not in stopwords) ]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypVMiZFvavED"
   },
   "source": [
    "### 3. Field 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2z-E-z7oNhZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field, LabelField, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BgIwbNcVO6i"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenizer_morphs, lower=True, batch_first = True) # sequential data, tokenizer라는 토크나이저 사용 / Text 처리하는 방법을 정의\n",
    "LABEL = LabelField(sequential=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-nm983la2zl"
   },
   "source": [
    "### 4. TabularDataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHs7OjgpYNrx"
   },
   "outputs": [],
   "source": [
    "raw_datafields = [(\"filename\", None), \n",
    "                 (\"date\", None), (\"NewsPaper\", None),\n",
    "                 (\"Topic\", LABEL), (\"News\", TEXT)] \n",
    "\n",
    "train_data = TabularDataset(\n",
    "        path=data_path_train,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)\n",
    "\n",
    "test_data= TabularDataset(\n",
    "        path=data_path_test,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtjPh-RFeDii"
   },
   "source": [
    "### 5. Vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x60f5nBx5xrI"
   },
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "TEXT.build_vocab(train_data, min_freq=10)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKOj-h-683HM",
    "outputId": "a1c43d47-7583-40a2-9dcb-81ff55e0221a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7fc494fc6730>, {'IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8})\n"
     ]
    }
   ],
   "source": [
    "#결과 확인\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 사전학습 임베딩 불러오기 \n",
    "Reference: https://rohit-agrawal.medium.com/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDP4WfCGgMVQ"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#word2vec 형태소 모델의 임베딩 사용\n",
    "path = '/content/gdrive/My Drive/model/'\n",
    "Word2Vec_300D_token_model = KeyedVectors.load_word2vec_format(path + 'Word2Vec_300D_token.model', binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210,
     "referenced_widgets": [
      "21d176e4156f476dad71eca827f6f6d5",
      "e5ec77296fb04aa9900fc6db471728f9",
      "1681d6f4a85f448a803fa81388ffafd5",
      "1907d7f9a4ca4eaea72f2aa02c66192d",
      "620576546b0f44dcbc5268112801d258",
      "af8d9136e297433490b835eb60d7565f",
      "edfd88f13a154ca3b16215ccd75b6890",
      "856c3652910046acb236a796bf12828b"
     ]
    },
    "id": "GEFynT5k56Oz",
    "outputId": "bd86b176-a5df-4eec-ed56-f2d947a390db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d176e4156f476dad71eca827f6f6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14639.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_vectors = []\n",
    "\n",
    "for token, idx in tqdm_notebook(TEXT.vocab.stoi.items()):\n",
    "    if token in Word2Vec_300D_token_model.wv.vocab.keys(): #사전학습 임베딩 모델에 해당 토큰의 임베딩 값이 있을 경우 그 값을 가져옴\n",
    "        word2vec_vectors.append(torch.FloatTensor(Word2Vec_300D_token_model[token]))\n",
    "    else:\n",
    "        word2vec_vectors.append(torch.randn(300)) #사전학습 임베딩 모델에 임베딩 값이 없을 경우 랜덤으로 설정\n",
    "        \n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi, word2vec_vectors, 300) #Vocab 각 토큰의 임베딩 값 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Iterator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZWB5Hc4pu_c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=lambda x: len(x.News), #데이터를 그룹화하는데 사용하는 함수\n",
    " sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6ORHo2kwSJO"
   },
   "source": [
    "### 8 CNN Model\n",
    "Reference: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0O48JJ6HwQNL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUIrxfOLwoDY"
   },
   "outputs": [],
   "source": [
    "#parameters 설정\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 9\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#모델에 parameters 입력\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSI1Tb9KxHJH",
    "outputId": "eb742865-8a59-4f10-cbbf-d4149603a532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2954e-02, -1.1642e-01,  4.9755e-01,  ...,  1.6532e+00,\n",
       "          1.8065e-01,  8.7345e-01],\n",
       "        [-9.2371e-01,  1.0091e+00, -1.9192e+00,  ...,  1.1858e+00,\n",
       "          2.5580e-01, -1.1186e+00],\n",
       "        [ 9.8296e-02,  6.8959e-02, -9.7626e-02,  ...,  1.9529e-02,\n",
       "         -4.3655e-02,  5.1375e-02],\n",
       "        ...,\n",
       "        [-2.6780e-02, -4.1724e-02,  1.4282e-01,  ..., -1.1069e-02,\n",
       "         -1.3842e-02,  5.1257e-02],\n",
       "        [-5.7113e-02, -1.0315e-01,  1.0424e-01,  ..., -6.7090e-02,\n",
       "          3.6692e-02,  4.1873e-02],\n",
       "        [-7.6801e-02, -3.9502e-02,  7.4451e-04,  ...,  4.1259e-02,\n",
       "          2.8716e-03,  5.0831e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델에 사전학습 임베딩값 가져오기\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuJRrWw-zSHI"
   },
   "outputs": [],
   "source": [
    "# <pad> 토큰에 대해 초기 임베딩값을 0으로 설정 \n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BecAUQtY28lS"
   },
   "source": [
    "### 9. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1osmRp1272N"
   },
   "outputs": [],
   "source": [
    "#optimizer와 loss function 정의\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyvIg-gL3HON"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4zn8Bnt3_ra"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.News)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Topic)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.Topic)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aUFJzequiNt"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.News)\n",
    "            \n",
    "            loss = criterion(predictions, batch.Topic)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.Topic)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZztHqeo4Mnt"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1R6gm194VeQ",
    "outputId": "3e83baba-a3c3-4d62-c3e1-cda798c55e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 1.939 | Train Acc: 33.11%\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 1.062 | Train Acc: 65.92%\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.713 | Train Acc: 76.64%\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.507 | Train Acc: 83.57%\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.342 | Train Acc: 89.47%\n",
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.227 | Train Acc: 93.69%\n",
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.141 | Train Acc: 96.36%\n",
      "Epoch: 08 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.090 | Train Acc: 98.04%\n",
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.058 | Train Acc: 98.79%\n",
      "Epoch: 10 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.037 | Train Acc: 99.56%\n",
      "Epoch: 11 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.028 | Train Acc: 99.61%\n",
      "Epoch: 12 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.022 | Train Acc: 99.80%\n",
      "Epoch: 13 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.88%\n",
      "Epoch: 14 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.014 | Train Acc: 99.82%\n",
      "Epoch: 15 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.011 | Train Acc: 99.89%\n",
      "Epoch: 16 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.009 | Train Acc: 99.91%\n",
      "Epoch: 17 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.008 | Train Acc: 99.93%\n",
      "Epoch: 18 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.007 | Train Acc: 99.92%\n",
      "Epoch: 19 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.98%\n",
      "Epoch: 20 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.94%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "    torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TV4wXvoXaqL8",
    "outputId": "a742c2b8-3624-457c-98dd-32df3a7a0426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.896 | Test Acc: 79.43%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut5-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFaKhJIkMd1N"
   },
   "source": [
    "### 11. User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fqkgqz_RS9DG"
   },
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer_morphs(sentence)\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "    return max_preds.item()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "시도1(CNN-Word2Vec형태소).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1681d6f4a85f448a803fa81388ffafd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af8d9136e297433490b835eb60d7565f",
      "max": 14639,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_620576546b0f44dcbc5268112801d258",
      "value": 14639
     }
    },
    "1907d7f9a4ca4eaea72f2aa02c66192d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_856c3652910046acb236a796bf12828b",
      "placeholder": "​",
      "style": "IPY_MODEL_edfd88f13a154ca3b16215ccd75b6890",
      "value": " 14639/14639 [00:00&lt;00:00, 52762.37it/s]"
     }
    },
    "21d176e4156f476dad71eca827f6f6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1681d6f4a85f448a803fa81388ffafd5",
       "IPY_MODEL_1907d7f9a4ca4eaea72f2aa02c66192d"
      ],
      "layout": "IPY_MODEL_e5ec77296fb04aa9900fc6db471728f9"
     }
    },
    "620576546b0f44dcbc5268112801d258": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "856c3652910046acb236a796bf12828b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af8d9136e297433490b835eb60d7565f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ec77296fb04aa9900fc6db471728f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfd88f13a154ca3b16215ccd75b6890": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
